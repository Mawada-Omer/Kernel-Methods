{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from cvxopt import solvers\n",
    "from cvxopt import matrix\n",
    "from cvxopt import spmatrix\n",
    "from cvxopt import sparse\n",
    "from collections import deque\n",
    "#################\n",
    "\n",
    "\"\"\"\n",
    "Group: Kernels Samplers ( Francis Anokye & Aissatou Ndoye)\n",
    "Data Challenge :  kernel methods in Machine learning\n",
    "Professors: Jean Phillpe Vert & Julien Mairal\n",
    "TA: Romain Menegaux \n",
    "Description:\n",
    "-------------\n",
    "This main script file implements a kernel SVM which uses vanilla k-spectrum feature embedding and \n",
    "(k,m)-mismatch embedding as a multiple kernel. This multiple kernel handles all the operations (gram matrix computation, \n",
    "function evaluation) and then after we predict on the test data and generate our submission file. \n",
    "\"\"\"\n",
    "############################################# KERNELS ##############################################\n",
    "class Kernel():\n",
    "       \n",
    "    def gaussian(sigma):\n",
    "        return lambda x, y : 1/(np.sqrt(2*np.pi)*sigma) * np.exp(-np.linalg.norm(x - y)**2/(2*sigma**2))\n",
    "    \n",
    "    def linear():\n",
    "        return lambda x, y: np.dot(x, y)\n",
    "    \n",
    "    def polynomial(c, n):\n",
    "        return lambda x, y : (np.dot(x, y) + c)**n\n",
    "    \n",
    "    def spectrum():\n",
    "        def f(x, y):\n",
    "            prod_scal = 0\n",
    "            for kmer in x:\n",
    "                if kmer in y:\n",
    "                    prod_scal += x[kmer]*y[kmer]\n",
    "            return prod_scal\n",
    "        return f\n",
    "    \n",
    "    def mismatch():\n",
    "        def f(x, y):\n",
    "            prod_scal = 0\n",
    "            for idx in x:\n",
    "                if idx in y:\n",
    "                    prod_scal += x[idx]*y[idx]\n",
    "            return prod_scal\n",
    "        return f\n",
    "    \n",
    "    def sparse_gaussian(sigma):\n",
    "        def f(x, y):\n",
    "            ps = Kernel.mismatch()\n",
    "            norm = ps(x, x) - 2*ps(x, y) + ps(y,y)\n",
    "            return 1/(np.sqrt(2*np.pi)*sigma) * np.exp(-norm/(2*sigma**2))\n",
    "        return f\n",
    "    \n",
    "    def sparse_poly(c, n):\n",
    "        def f(x, y):\n",
    "            ps = Kernel.mismatch()\n",
    "            return (ps(x,y) + c)**n\n",
    "        return f\n",
    "    \n",
    "    def __init__(self, func, normalized = False):\n",
    "        self.kernel = func\n",
    "        self.normalized = normalized\n",
    "        self.diag = np.array([])\n",
    "        \n",
    "    def gram(self, data):\n",
    "        n = len(data)\n",
    "        K = np.zeros((n, n))\n",
    "        print(\"Generating Gram Matrix\")\n",
    "        for i in tqdm(range(n)):\n",
    "            for j in range(i+1):\n",
    "                prod_scal = self.kernel(data[i], data[j])\n",
    "                K[i, j] = prod_scal\n",
    "                K[j, i] = prod_scal\n",
    "        \n",
    "        if self.normalized:\n",
    "            self.diag = np.sqrt(np.diag(K))\n",
    "            print(self.diag.shape)\n",
    "            for i in range(n):\n",
    "                K[i, :] = K[i,:]/self.diag[i]\n",
    "                K[:, i] = K[:, i]/self.diag[i]\n",
    "        return K\n",
    "    \n",
    "    def eval_f(self, x, alpha, data):\n",
    "        if self.normalized:\n",
    "            square_norm_x = np.sqrt(self.kernel(x, x))\n",
    "            result = np.sum([(alpha[i]*self.kernel(x, xi))/(square_norm_x * self.diag[i]) for i, xi in enumerate(data)])\n",
    "        else:\n",
    "            result =  np.sum([alpha[i]*self.kernel(x, xi) for i, xi in enumerate(data)])\n",
    "        return result \n",
    "\n",
    "###################################### Kernel_SVM #################################################\n",
    "class Kernel_SVM():\n",
    "    \n",
    "    def SVM(K, y, lmda):\n",
    "        print(\"Optimizing\")\n",
    "        solvers.options['show_progress'] = False\n",
    "        n = len(y)\n",
    "        q = -matrix(y, (n, 1), tc='d')\n",
    "        h = matrix(np.concatenate([np.ones(n)/(2*lmda*n), np.zeros(n)]).reshape((2*n, 1)))\n",
    "        P = matrix(K)\n",
    "        Gtop = spmatrix(y, range(n), range(n))\n",
    "        G = sparse([Gtop, -Gtop])\n",
    "        sol = solvers.qp(P, q, G, h)['x']\n",
    "    \n",
    "        return sol\n",
    "############################################ Multiple Spectrum Kernel ##################################\n",
    "def project(v):\n",
    "        mu = list(v)\n",
    "        mu.sort()\n",
    "        cumul_sum = np.cumsum(mu)\n",
    "        rho = np.max([j for j in range(0, len(mu)) if mu[j] - 1/(j+1)*(cumul_sum[j] - 1) > 0])\n",
    "        \n",
    "        theta = 1/(rho+1)*(cumul_sum[rho] - 1)\n",
    "        return np.array([max(0, vi - theta) for vi in v])\n",
    "\n",
    "def MKL(kernels, y, lmda, T):\n",
    "    m = len(kernels)\n",
    "    d = np.array([1/m for k in range(m)])\n",
    "    for t in range(T):\n",
    "        K = np.zeros_like(kernels[0])\n",
    "        for i, Km in enumerate(kernels):\n",
    "            K = K + d[i]*Km\n",
    "        alpha = Kernel_SVM.SVM(K, y, lmda) \n",
    "        grad = [-0.5*lmda*np.dot(alpha.T, np.dot(Km, alpha))[0][0] for Km in kernels]\n",
    "        step = 0.01\n",
    "        d = project(d - step*np.array(grad)) \n",
    "    return d\n",
    "        \n",
    "#########################################\n",
    "def write_predictions(predictions, out_fname):\n",
    "    data = [[int(np.abs((pred+1)//2))] for i, pred in enumerate(predictions)]\n",
    "    data = np.concatenate([[['Bound']], data])\n",
    "    data_frame = pd.DataFrame(data=data[1:,:], columns=data[0])\n",
    "    data_frame.index.name = 'Id'\n",
    "    data_frame.to_csv(out_fname)\n",
    "    \n",
    "def kernel_train(kernel, training_data, ytrain, lmda):\n",
    "    K = kernel.gram(training_data)\n",
    "    alpha = Kernel_SVM.SVM(K, ytrain, lmda)\n",
    "    return alpha\n",
    "\n",
    "def kernel_predict(kernel, alpha, training, test):\n",
    "    predict = []\n",
    "    for x in tqdm(test):\n",
    "        predict.append(np.sign(kernel.eval_f(x, alpha, training)))\n",
    "    return predict\n",
    "\n",
    "def score(predict, truth):\n",
    "    return sum([int(predict[i]==truth[i]) for i in range(len(truth))])/len(truth)\n",
    "\n",
    "def split_data(dataset, y, k, m):\n",
    "    dataset.populate_kmer_set(k)\n",
    "    dataset.mismatch_preprocess(k, m)\n",
    "    idx = range(len(dataset.data))\n",
    "    pairs = []\n",
    "    data_tranches = [idx[500*i : 500*i+ 500] for i in range(4)]\n",
    "    label_tranches = [y[500*i: 500*i + 500] for i in range(4)]\n",
    "    for i in range(4):\n",
    "        test, ytest = data_tranches[i], label_tranches[i]\n",
    "        train = np.concatenate([data_tranches[j] for j in range(4) if j != i])\n",
    "        ytrain = np.concatenate([label_tranches[j] for j in range(4) if j != i])\n",
    "        \n",
    "        pairs.append((train, ytrain, test, ytest))\n",
    "    return pairs\n",
    "\n",
    "############################################### Data Loader #######################################\n",
    "class DataLoader():\n",
    "    \n",
    "    def __init__(self, fname):\n",
    "        self.X = pd.read_csv(fname)['seq']\n",
    "        self.data = self.X\n",
    "        self.kmer_set = {}\n",
    "        self.neigborhoods = {}\n",
    "        self.alph = \"GATC\"\n",
    "        self.precomputed = {}\n",
    "        \n",
    "    def spectrum_preprocess(self, k):\n",
    "        n = self.X.shape[0]\n",
    "        d = len(self.X[0])\n",
    "        embedding = [{} for x in self.X]\n",
    "        print(\"Generating kmer embedding\")\n",
    "        for i,x in enumerate(tqdm(self.X)):\n",
    "            for j in range(d - k + 1):\n",
    "                kmer = x[j: j + k]\n",
    "                if kmer in embedding[i]:\n",
    "                    embedding[i][kmer] += 1\n",
    "                else:\n",
    "                    embedding[i][kmer] = 1\n",
    "        self.data = embedding\n",
    "        \n",
    "    def populate_kmer_set(self, k):\n",
    "        d = len(self.X[0])\n",
    "        idx = 0\n",
    "        print(\"Populating kmer set\")\n",
    "        for x in tqdm(self.X):\n",
    "            for j in range(d - k + 1):\n",
    "                kmer = x[j: j + k]\n",
    "                if kmer not in self.kmer_set:\n",
    "                    self.kmer_set[kmer] = idx\n",
    "                    idx +=1  \n",
    "            \n",
    "    def mismatch_preprocess(self, k, m):\n",
    "        n = self.X.shape[0]\n",
    "        d = len(self.X[0])\n",
    "        embedding = [{} for x in self.X]\n",
    "        print(\"Generating mismatch embedding\")\n",
    "        for i,x in enumerate(tqdm(self.X)):\n",
    "            for j in range(d - k + 1):\n",
    "                kmer = x[j: j + k]\n",
    "                if kmer not in self.precomputed:\n",
    "                    Mneighborhood = self.m_neighborhood(kmer, m)\n",
    "                    self.precomputed[kmer] = [self.kmer_set[neighbor] for neighbor in Mneighborhood if neighbor in self.kmer_set]\n",
    "                    \n",
    "                for idx in self.precomputed[kmer]:\n",
    "                    if idx in embedding[i]:\n",
    "                        embedding[i][idx] += 1\n",
    "                    else:\n",
    "                        embedding[i][idx] = 1\n",
    "        self.data = embedding\n",
    "            \n",
    "    def m_neighborhood(self, kmer, m):\n",
    "        mismatch_list = deque([(0, \"\")])\n",
    "        for letter in kmer:\n",
    "            num_candidates = len(mismatch_list)\n",
    "            for i in range(num_candidates):\n",
    "                mismatches, candidate = mismatch_list.popleft()\n",
    "                if mismatches < m :\n",
    "                    for a in self.alph:\n",
    "                        if a == letter :\n",
    "                            mismatch_list.append((mismatches, candidate + a))\n",
    "                        else:\n",
    "                            mismatch_list.append((mismatches + 1, candidate + a))\n",
    "                if mismatches == m:\n",
    "                    mismatch_list.append((mismatches, candidate + letter))\n",
    "        return [candidate for mismatches, candidate in mismatch_list]\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "print('''\n",
    "---------------------------------------------------------------------------------\n",
    "------Generating Submission File: This may take some time. Please be patient-----\n",
    "---------------------------------------------------------------------------------\n",
    "''')\n",
    "\n",
    "dataset = DataLoader('data/Xtr.csv')\n",
    "\n",
    "labels = pd.read_csv('data/Ytr.csv')\n",
    "y = 2.0 * np.array(labels['Bound']) - 1\n",
    "\n",
    "test = DataLoader('data/Xte.csv')\n",
    "\n",
    "dataset.X = pd.concat([dataset.X, test.X], axis = 0, ignore_index = True)\n",
    "\n",
    "dataset.populate_kmer_set(k = 12) #12 with mismatch of 2 in 1st 2 mismatch & 3 in 3rd produces a public score of 71.60 and private of 72.60\n",
    "dataset.mismatch_preprocess(k=12, m=2)#12,1\n",
    "Kernell_1 = Kernel(Kernel.mismatch()).gram(dataset.data)\n",
    "\n",
    "dataset.populate_kmer_set(k = 13)#13\n",
    "dataset.mismatch_preprocess(k=13, m=2)#13,1\n",
    "Kernell_2 = Kernel(Kernel.mismatch()).gram(dataset.data)\n",
    "\n",
    "dataset.populate_kmer_set(k = 15)#15\n",
    "dataset.mismatch_preprocess(k=15, m=3)#15,1\n",
    "Kernell_3 = Kernel(Kernel.mismatch()).gram(dataset.data)\n",
    "\n",
    "# Add kernels together\n",
    "K = Kernell_1 + Kernell_2 + Kernell_3 \n",
    "\n",
    "training = [i for i in range(2000)]\n",
    "testing = [i for i in range(2000, 3000)]\n",
    "\n",
    "lmda = 1.0#0.8\n",
    "\n",
    "alpha = Kernel_SVM.SVM(K[training][:, training], y, lmda)\n",
    "\n",
    "predictions = []\n",
    "for i in tqdm(testing):\n",
    "    val = 0\n",
    "    for k, j in enumerate(training):\n",
    "        val += alpha[k]*K[i, j]\n",
    "    predictions.append(np.sign(val))\n",
    "submission_file = \"Yte_final_last6.csv\"\n",
    "write_predictions(predictions, submission_file)\n",
    "print('')\n",
    "print('All Done...!!!')\n",
    "print('''\n",
    "---------------------------------------------------------------------------------------------------\n",
    "---------Submission File Generated: Thank you for your time and knowledge shared with us.----------\n",
    "---------------------------------------------------------------------------------------------------\n",
    "''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
